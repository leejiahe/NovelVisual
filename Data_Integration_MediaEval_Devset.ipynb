{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Integration on MediaEval Dev Dataset\n",
    "\n",
    "- Data cleaning on development set\n",
    "- We will look at the images that had been unzipped, process the images and save it into a dataframe\n",
    "- There are 3 files that we are working on which will be combined later\n",
    "    1. tweets.txt - The data contains the tweet text\n",
    "    2. users_features.csv - The data contain social information such as #friends, #followers, etc. \n",
    "    3. tweet_features.csv - The data contain tweet features such as number of positive emoticon, order pron, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import sys, os, requests, glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"./MediaEval/mediaeval2015/devset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Each Image\n",
    "\n",
    "1. Open each image, if there is an error that append the row to remove_list\n",
    "2. If the file extension of the image is not jpg, then save the file to jpg extension and delete the original file\n",
    "3. Drop all images that is in the remove_list\n",
    "\n",
    "We will drop rows that is in the remove_list, this allows us to work only with valid images\n",
    "\n",
    "The invalid images will arise during the downloading of the images from sites such as Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.join(df_path, 'Medieval2015_DevSet_Images')\n",
    "\n",
    "valid_list = []\n",
    "path_list = []\n",
    "event_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(images_path):\n",
    "    if len(dirs) == 0:\n",
    "        for file in files:\n",
    "            file_split = file.split('.')\n",
    "            event = file.split('_')[0]\n",
    "            path = os.path.join(root, file)\n",
    "            img = Image.open(os.path.join(root, file))\n",
    "            if file_split[-1] != 'jpg':\n",
    "                try:\n",
    "                    file_save = os.path.join(root, file_split[0] + '.jpg')\n",
    "                    img.save(file_save)\n",
    "                    os.remove(path)\n",
    "                except:\n",
    "                    os.remove(path)\n",
    "                    os.remove(file_save)\n",
    "            valid_list.append(file_split[0])\n",
    "            path_list.append(path)\n",
    "            event_list.append(event)\n",
    "\n",
    "df_images = pd.DataFrame({'imageId': valid_list, 'imagePath': path_list, 'event': event_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image id of sandyA and sandyB to sandy \n",
    "df_images['event'] = df_images['event'].apply(lambda x : 'sandy' if ((x == 'sandyA') | (x == 'sandyB')) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images.to_pickle('dev_images.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Cleaning on Devset Tweets\n",
    "\n",
    "- Objective is to extract the tweets\n",
    "- There are duplicates tweets in the data, so we will drop the duplicates by its tweetId. tweetId should be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetId</th>\n",
       "      <th>tweetText</th>\n",
       "      <th>userId</th>\n",
       "      <th>imageId(s)</th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263046056240115712</td>\n",
       "      <td>¿Se acuerdan de la película: “El día después d...</td>\n",
       "      <td>21226711</td>\n",
       "      <td>sandyA_fake_46</td>\n",
       "      <td>iAnnieM</td>\n",
       "      <td>Mon Oct 29 22:34:01 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262995061304852481</td>\n",
       "      <td>@milenagimon: Miren a Sandy en NY!  Tremenda i...</td>\n",
       "      <td>192378571</td>\n",
       "      <td>sandyA_fake_09</td>\n",
       "      <td>CarlosVerareal</td>\n",
       "      <td>Mon Oct 29 19:11:23 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262979898002534400</td>\n",
       "      <td>Buena la foto del Huracán Sandy, me recuerda a...</td>\n",
       "      <td>132303095</td>\n",
       "      <td>sandyA_fake_09</td>\n",
       "      <td>LucasPalape</td>\n",
       "      <td>Mon Oct 29 18:11:08 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262996108400271360</td>\n",
       "      <td>Scary shit #hurricane #NY http://t.co/e4JLBUfH</td>\n",
       "      <td>241995902</td>\n",
       "      <td>sandyA_fake_29</td>\n",
       "      <td>Haaaaarryyy</td>\n",
       "      <td>Mon Oct 29 19:15:33 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263018881839411200</td>\n",
       "      <td>My fave place in the world #nyc #hurricane #sa...</td>\n",
       "      <td>250315890</td>\n",
       "      <td>sandyA_fake_15</td>\n",
       "      <td>princess__natt</td>\n",
       "      <td>Mon Oct 29 20:46:02 +0000 2012</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetId                                          tweetText  \\\n",
       "0  263046056240115712  ¿Se acuerdan de la película: “El día después d...   \n",
       "1  262995061304852481  @milenagimon: Miren a Sandy en NY!  Tremenda i...   \n",
       "2  262979898002534400  Buena la foto del Huracán Sandy, me recuerda a...   \n",
       "3  262996108400271360     Scary shit #hurricane #NY http://t.co/e4JLBUfH   \n",
       "4  263018881839411200  My fave place in the world #nyc #hurricane #sa...   \n",
       "\n",
       "      userId      imageId(s)        username                       timestamp  \\\n",
       "0   21226711  sandyA_fake_46         iAnnieM  Mon Oct 29 22:34:01 +0000 2012   \n",
       "1  192378571  sandyA_fake_09  CarlosVerareal  Mon Oct 29 19:11:23 +0000 2012   \n",
       "2  132303095  sandyA_fake_09     LucasPalape  Mon Oct 29 18:11:08 +0000 2012   \n",
       "3  241995902  sandyA_fake_29     Haaaaarryyy  Mon Oct 29 19:15:33 +0000 2012   \n",
       "4  250315890  sandyA_fake_15  princess__natt  Mon Oct 29 20:46:02 +0000 2012   \n",
       "\n",
       "  label  \n",
       "0  fake  \n",
       "1  fake  \n",
       "2  fake  \n",
       "3  fake  \n",
       "4  fake  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_tweets_path = os.path.join(df_path, 'tweets.txt')\n",
    "df_raw_tweets = pd.read_csv(df_raw_tweets_path, sep = \"\\t\")\n",
    "df_raw_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14277 entries, 0 to 14276\n",
      "Data columns (total 7 columns):\n",
      "tweetId       14277 non-null int64\n",
      "tweetText     14277 non-null object\n",
      "userId        14277 non-null int64\n",
      "imageId(s)    14277 non-null object\n",
      "username      14277 non-null object\n",
      "timestamp     14277 non-null object\n",
      "label         14277 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 780.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates Tweets\n",
    "\n",
    "- Drop duplicates from tweetId which should be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Drop duplicate tweets\n",
    "df_raw_tweets.drop_duplicates('tweetId', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_tweets.to_pickle('dev_raw_tweets.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Cleaning on Devset User Features\n",
    "\n",
    "- Objective is to extract some user features from the data such as #friends, #followers etc.\n",
    "- Similar to previous step, we will drop duplicates from tweetId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>num_friends</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>folfriend_ratio</th>\n",
       "      <th>times_listed</th>\n",
       "      <th>has_url</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>num_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263046056240115712</td>\n",
       "      <td>283</td>\n",
       "      <td>1651</td>\n",
       "      <td>5.833922</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>43811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262995061304852481</td>\n",
       "      <td>2189</td>\n",
       "      <td>95637</td>\n",
       "      <td>43.689810</td>\n",
       "      <td>737</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>54293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262979898002534400</td>\n",
       "      <td>1972</td>\n",
       "      <td>1701</td>\n",
       "      <td>0.862576</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>34414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262996108400271360</td>\n",
       "      <td>267</td>\n",
       "      <td>235</td>\n",
       "      <td>0.880150</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263018881839411200</td>\n",
       "      <td>193</td>\n",
       "      <td>181</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>25754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id   num_friends   num_followers   folfriend_ratio  \\\n",
       "0  263046056240115712           283            1651          5.833922   \n",
       "1  262995061304852481          2189           95637         43.689810   \n",
       "2  262979898002534400          1972            1701          0.862576   \n",
       "3  262996108400271360           267             235          0.880150   \n",
       "4  263018881839411200           193             181          0.937824   \n",
       "\n",
       "    times_listed   has_url   is_verified   num_tweets  \n",
       "0             64     False         False        43811  \n",
       "1            737      True         False        54293  \n",
       "2             13     False         False        34414  \n",
       "3              0     False         False        17837  \n",
       "4              0     False         False        25754  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_path = os.path.join(df_path, 'DatasetFeatures/user_features.csv') \n",
    "df_user = pd.read_csv(df_user_path)\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14483 entries, 0 to 14482\n",
      "Data columns (total 8 columns):\n",
      "tweet_id            14483 non-null int64\n",
      " num_friends        14483 non-null int64\n",
      " num_followers      14483 non-null int64\n",
      " folfriend_ratio    14483 non-null float64\n",
      " times_listed       14483 non-null int64\n",
      " has_url            14483 non-null bool\n",
      " is_verified        14483 non-null bool\n",
      " num_tweets         14483 non-null int64\n",
      "dtypes: bool(2), float64(1), int64(5)\n",
      "memory usage: 707.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_user.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns name cleaning\n",
    "\n",
    "- Remove leading whitespace in the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.columns = df_user.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates Tweets\n",
    "\n",
    "- Drop duplicates from tweetId which should be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df_user.drop_duplicates('tweet_id', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to Pickel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.to_pickle('dev_users.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Cleaning on Tweets Features\n",
    "\n",
    "- Objective is to extract tweet features from tweets such as num_words, contains quest_marks, etc.\n",
    "- We will handle some of the null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text_length</th>\n",
       "      <th>contains_questmark</th>\n",
       "      <th>num_questmark</th>\n",
       "      <th>contains_exclammark</th>\n",
       "      <th>num_exclammark</th>\n",
       "      <th>contains_happyemo</th>\n",
       "      <th>contains_sademo</th>\n",
       "      <th>contains_firstorderpron</th>\n",
       "      <th>contains_secondorderpron</th>\n",
       "      <th>contains_thirdorderpron</th>\n",
       "      <th>num_uppercasechars</th>\n",
       "      <th>num_possentiwords</th>\n",
       "      <th>num_negsentiwords</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_URLs</th>\n",
       "      <th>num_retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263046056240115712</td>\n",
       "      <td>22</td>\n",
       "      <td>134</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262995061304852481</td>\n",
       "      <td>18</td>\n",
       "      <td>133</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262979898002534400</td>\n",
       "      <td>17</td>\n",
       "      <td>116</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262996108400271360</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263018881839411200</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id   num_words   text_length   contains_questmark  \\\n",
       "0  263046056240115712          22           134                 True   \n",
       "1  262995061304852481          18           133                False   \n",
       "2  262979898002534400          17           116                False   \n",
       "3  262996108400271360           4            46                False   \n",
       "4  263018881839411200          10            90                False   \n",
       "\n",
       "    num_questmark   contains_exclammark   num_exclammark   contains_happyemo  \\\n",
       "0               1                 False                0               False   \n",
       "1               0                  True                2               False   \n",
       "2               0                 False                0               False   \n",
       "3               0                 False                0               False   \n",
       "4               0                 False                0               False   \n",
       "\n",
       "    contains_sademo  contains_firstorderpron  contains_secondorderpron  \\\n",
       "0             False                    False                     False   \n",
       "1             False                    False                     False   \n",
       "2             False                    False                     False   \n",
       "3             False                    False                     False   \n",
       "4             False                    False                     False   \n",
       "\n",
       "   contains_thirdorderpron   num_uppercasechars   num_possentiwords  \\\n",
       "0                     True                    3                 0.0   \n",
       "1                     True                   14                 0.0   \n",
       "2                    False                    5                 0.0   \n",
       "3                    False                    1                 0.0   \n",
       "4                    False                    1                 1.0   \n",
       "\n",
       "    num_negsentiwords   num_mentions   num_hashtags   num_URLs   num_retweets  \n",
       "0                 0.0              0              1          1              0  \n",
       "1                 0.0              1              0          0              0  \n",
       "2                 0.0              0              2          1              0  \n",
       "3                 2.0              0              2          1              0  \n",
       "4                 0.0              0              4          1              0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can skip\n",
    "df_tweets_path = os.path.join(df_path, 'DatasetFeatures/tweet_features.csv') \n",
    "df_tweets_features = pd.read_csv(df_tweets_path)\n",
    "df_tweets_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14483 entries, 0 to 14482\n",
      "Data columns (total 19 columns):\n",
      "tweet_id                     14483 non-null int64\n",
      " num_words                   14483 non-null int64\n",
      " text_length                 14483 non-null int64\n",
      " contains_questmark          14483 non-null bool\n",
      " num_questmark               14483 non-null int64\n",
      " contains_exclammark         14483 non-null bool\n",
      " num_exclammark              14483 non-null int64\n",
      " contains_happyemo           14483 non-null bool\n",
      " contains_sademo             14483 non-null bool\n",
      " contains_firstorderpron     11816 non-null object\n",
      " contains_secondorderpron    11816 non-null object\n",
      " contains_thirdorderpron     11816 non-null object\n",
      " num_uppercasechars          14483 non-null int64\n",
      " num_possentiwords           11816 non-null float64\n",
      " num_negsentiwords           11816 non-null float64\n",
      " num_mentions                14483 non-null int64\n",
      " num_hashtags                14483 non-null int64\n",
      " num_URLs                    14483 non-null int64\n",
      " num_retweets                14483 non-null int64\n",
      "dtypes: bool(4), float64(2), int64(10), object(3)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns name cleaning\n",
    "\n",
    "- Remove leading whitespace in the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_features.columns = df_tweets_features.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Imputation on orderpron features\n",
    "\n",
    "Taking for instance, *contains_firstorderpron* column, it can be seen that the nan value is caused by the tweet text, in this case, text having all hashtags and url and thus not having necessary information to infer *contain_firstorderpron* information, so all the nan value is replaced by False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text_length</th>\n",
       "      <th>contains_questmark</th>\n",
       "      <th>num_questmark</th>\n",
       "      <th>contains_exclammark</th>\n",
       "      <th>num_exclammark</th>\n",
       "      <th>contains_happyemo</th>\n",
       "      <th>contains_sademo</th>\n",
       "      <th>contains_firstorderpron</th>\n",
       "      <th>contains_secondorderpron</th>\n",
       "      <th>contains_thirdorderpron</th>\n",
       "      <th>num_uppercasechars</th>\n",
       "      <th>num_possentiwords</th>\n",
       "      <th>num_negsentiwords</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_URLs</th>\n",
       "      <th>num_retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>263111677485142017</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>262977091983785985</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>263129115207536640</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id  num_words  text_length  contains_questmark  \\\n",
       "8   263111677485142017          5           69               False   \n",
       "9   262977091983785985          2           36               False   \n",
       "11  263129115207536640          3           45               False   \n",
       "\n",
       "    num_questmark  contains_exclammark  num_exclammark  contains_happyemo  \\\n",
       "8               0                False               0              False   \n",
       "9               0                False               0              False   \n",
       "11              0                False               0              False   \n",
       "\n",
       "    contains_sademo contains_firstorderpron contains_secondorderpron  \\\n",
       "8             False                     NaN                      NaN   \n",
       "9             False                     NaN                      NaN   \n",
       "11            False                     NaN                      NaN   \n",
       "\n",
       "   contains_thirdorderpron  num_uppercasechars  num_possentiwords  \\\n",
       "8                      NaN                   0                NaN   \n",
       "9                      NaN                   0                NaN   \n",
       "11                     NaN                   0                NaN   \n",
       "\n",
       "    num_negsentiwords  num_mentions  num_hashtags  num_URLs  num_retweets  \n",
       "8                 NaN             0             5         1             0  \n",
       "9                 NaN             0             2         1             0  \n",
       "11                NaN             0             3         1             0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_orderpron_nan = df_tweets_features.loc[:, 'contains_firstorderpron'].isna()\n",
    "df_tweets_features.loc[first_orderpron_nan,:].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "order_pron = ['contains_firstorderpron', 'contains_secondorderpron', 'contains_thirdorderpron']\n",
    "df_tweets_features.loc[:, order_pron] = df_tweets_features.loc[:, order_pron].fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation on number sentiment word features\n",
    "\n",
    "Similarly, the number of sentiment word features can be set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "entiwords = ['num_possentiwords', 'num_negsentiwords']\n",
    "df_tweets_features.loc[:, entiwords] = df_tweets_features.loc[:, entiwords].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_tweets_features.to_pickle('dev_tweets_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_features = pd.read_pickle('dev_tweets_features.pkl')\n",
    "df_images = pd.read_pickle('dev_images.pkl')\n",
    "df_raw_tweets = pd.read_pickle('dev_raw_tweets.pkl')\n",
    "df_users = pd.read_pickle('dev_users.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging raw tweets with tweet features\n",
    "- Merge raw tweets with tweet features by the tweetId which is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_raw_tweets, df_tweets_features, left_on = 'tweetId', right_on = 'tweet_id', how = 'inner')\n",
    "df.drop('tweetId', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging users with the combined dataframe\n",
    "- Merge users with the dataframe by the tweet_id which is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_users, on = 'tweet_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging images with the combined dataframe\n",
    "- Merge images with the dataframe by imageId which is unique\n",
    "- The number of rows of the resulting dataframe had been halved. This is because some images had not been found or unable to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_images, left_on = 'imageId(s)', right_on = 'imageId', how = 'inner')\n",
    "df.drop('imageId(s)', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping irrelevant features\n",
    "\n",
    "Features | Reason\n",
    "-|-\n",
    "userId | Offer no additional info\n",
    "username | Offer no additional info\n",
    "tweet_id | Offer no additional info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['userId', 'username', 'tweet_id']\n",
    "df.drop(drop_cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Timestamp to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the timestamp has an extra whitespace, so we need to remove that whitespace\n",
    "df.loc[:, 'timestamp'] = df.loc[:, 'timestamp'].str.replace(': ', ':')\n",
    "\n",
    "df.loc[:, 'timestamp'] = pd.to_datetime(df.loc[:, 'timestamp'], \\\n",
    "               format = '%a %b %d %H:%M:%S +0000 %Y')\n",
    "\n",
    "df.set_index('timestamp', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Boolean values to int\n",
    "\n",
    "- Get all the columns which has boolean dtype\n",
    "- Apply lambda function to convert boolean to integer elementwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = df.columns[df.dtypes == 'bool']\n",
    "df.loc[:, bool_cols] = df.loc[:, bool_cols].applymap(lambda x : 1 if x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting label to int\n",
    "- Convert label features to integer\n",
    "- There is another label called humor, which according to the paper, can be treated as fake\n",
    "- If you compare with annotation column found in images.txt, the corresponding label is fake for all humor values \n",
    "- For real label, it is 1. For fake label, it is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake     6634\n",
       "real     4834\n",
       "humor    2604\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'label'] = df.loc[:, 'label'].apply(lambda x : 1 if x == 'real' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove events that has too little images\n",
    "- Subsequent images processing require quite a large set of images to make prediction\n",
    "- We will drop events that has lesser than 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_image = df.loc[:, 'imageId'].drop_duplicates().str.split('_').str.get(0).value_counts() < 10\n",
    "drop_idx = df.loc[:, 'imageId'].apply(lambda x: x.split('_')[0] not in drop_image.index[drop_image])\n",
    "df = df.loc[drop_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sandy                 12256\n",
       "malaysia                501\n",
       "boston                  404\n",
       "sochi                   401\n",
       "columbianChemicals      185\n",
       "Name: event, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'event'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df.to_pickle('dev.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "- The majority of the features had been converted to integer or float\n",
    "- The rest of the features that are still objects will be used as such\n",
    "\n",
    "Object features | Reason\n",
    "-|-\n",
    "tweetText | To be used for image captioning  \n",
    "image_id | To be used for images statistics\n",
    "image_path | To be used for image_captioning\n",
    "event | To be used for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 13747 entries, 2012-10-29 22:34:01 to 2014-03-19 14:43:18\n",
      "Data columns (total 30 columns):\n",
      "tweetText                   13747 non-null object\n",
      "label                       13747 non-null int64\n",
      "num_words                   13747 non-null int64\n",
      "text_length                 13747 non-null int64\n",
      "contains_questmark          13747 non-null int64\n",
      "num_questmark               13747 non-null int64\n",
      "contains_exclammark         13747 non-null int64\n",
      "num_exclammark              13747 non-null int64\n",
      "contains_happyemo           13747 non-null int64\n",
      "contains_sademo             13747 non-null int64\n",
      "contains_firstorderpron     13747 non-null int64\n",
      "contains_secondorderpron    13747 non-null int64\n",
      "contains_thirdorderpron     13747 non-null int64\n",
      "num_uppercasechars          13747 non-null int64\n",
      "num_possentiwords           13747 non-null float64\n",
      "num_negsentiwords           13747 non-null float64\n",
      "num_mentions                13747 non-null int64\n",
      "num_hashtags                13747 non-null int64\n",
      "num_URLs                    13747 non-null int64\n",
      "num_retweets                13747 non-null int64\n",
      "num_friends                 13747 non-null int64\n",
      "num_followers               13747 non-null int64\n",
      "folfriend_ratio             13747 non-null float64\n",
      "times_listed                13747 non-null int64\n",
      "has_url                     13747 non-null int64\n",
      "is_verified                 13747 non-null int64\n",
      "num_tweets                  13747 non-null int64\n",
      "imageId                     13747 non-null object\n",
      "imagePath                   13747 non-null object\n",
      "event                       13747 non-null object\n",
      "dtypes: float64(3), int64(23), object(4)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
